{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.nnet as conv\n",
    "import numpy as np\n",
    "'''\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"http://10.0.0.5:8080/video?x.mjpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[83]:\n",
    "\n",
    "## A randomly initialized convolutional layer with 2 feature maps\n",
    "# Input : (RGB) 3x639x516\n",
    "# Receptive Field size : 9x9\n",
    "\n",
    "# Random element\n",
    "rng = np.random.RandomState(23455)\n",
    "\n",
    "# Input \n",
    "input = T.tensor4('input')\n",
    "\n",
    "# weight shape, w [depth_of_layer_m,depth_of_layer_m-1,filter_height,filter_width]\n",
    "wshape = (2,3,9,9)\n",
    "\n",
    "# bound on w values\n",
    "wbound = np.sqrt(3 * 9 * 9)\n",
    "\n",
    "# weight initialize with random numbers\n",
    "wval = np.asarray(rng.uniform(low=-1/wbound,high=1/wbound,size=wshape),dtype=input.dtype)\n",
    "\n",
    "# build shared variable w\n",
    "w = theano.shared(wval,name='w')\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "# setup bias\n",
    "b = theano.shared(np.asarray(rng.uniform(-0.5,0.5,(2,)),dtype=input.dtype),name='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build symbolic expression for convolution layer\n",
    "conv_out = conv.conv2d(input,w)\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "# associate the bias term with the output of conv_layer\n",
    "output = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "# compile function\n",
    "convf = theano.function([input],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel for sharpening image\n",
    "#Create the identity filter, but with the 1 shifted to the right!\n",
    "kernel = np.zeros( (8,8), np.float32)\n",
    "kernel[4,4] = 2.0   #Identity, times two! \n",
    "\n",
    "#Create a box filter:\n",
    "boxFilter = np.ones( (12,12), np.float32) / 81.0\n",
    "\n",
    "#Subtract the two:\n",
    "kernel = kernel - boxFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    if frame.shape[0] > 0 and frame.shape[1] > 0:\n",
    "        resized = cv2.resize(frame,(480,270), interpolation = cv2.INTER_CUBIC)\n",
    "        # sharpen image\n",
    "        #resized = cv2.filter2D(resized, -1, kernel)\n",
    "        cv2.imshow('frame',resized)\n",
    "        #img = np.asarray(resized, dtype=theano.config.floatX)/256.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        #img_ = img.transpose(2,0,1).reshape(1,3,480,270)\n",
    "        #omg = convf(img_)\n",
    "        #cv2.imshow('f01',omg[0,0,:,:])\n",
    "        #cv2.imshow('f02',omg[0,1,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
